{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2bc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Load the data file into a Pandas Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48bc0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                   int64\n",
      "CPU_LOAD             int64\n",
      "MEMORY_LEAK_LOAD     int64\n",
      "DELAY                int64\n",
      "ERROR_1000           int64\n",
      "ERROR_1001           int64\n",
      "ERROR_1002           int64\n",
      "ERROR_1003           int64\n",
      "ROOT_CAUSE          object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CPU_LOAD</th>\n",
       "      <th>MEMORY_LEAK_LOAD</th>\n",
       "      <th>DELAY</th>\n",
       "      <th>ERROR_1000</th>\n",
       "      <th>ERROR_1001</th>\n",
       "      <th>ERROR_1002</th>\n",
       "      <th>ERROR_1003</th>\n",
       "      <th>ROOT_CAUSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY_LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY_LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY_LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MEMORY_LEAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NETWORK_DELAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  CPU_LOAD  MEMORY_LEAK_LOAD  DELAY  ERROR_1000  ERROR_1001  ERROR_1002  \\\n",
       "0   1         0                 0      0           0           1           0   \n",
       "1   2         0                 0      0           0           0           0   \n",
       "2   3         0                 1      1           0           0           1   \n",
       "3   4         0                 1      0           1           1           0   \n",
       "4   5         1                 1      0           1           0           1   \n",
       "\n",
       "   ERROR_1003     ROOT_CAUSE  \n",
       "0           1    MEMORY_LEAK  \n",
       "1           1    MEMORY_LEAK  \n",
       "2           1    MEMORY_LEAK  \n",
       "3           1    MEMORY_LEAK  \n",
       "4           0  NETWORK_DELAY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptom_data = pd.read_csv(\"root_cause_analysis.csv\")\n",
    "\n",
    "#Explore the data loaded\n",
    "print(symptom_data.dtypes)\n",
    "symptom_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4215977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature variables : (900, 7)\n",
      "Shape of target variable : (900, 3)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense-Layer-1 (Dense)       (None, 128)               1024      \n",
      "                                                                 \n",
      " Dense-Layer-2 (Dense)       (None, 128)               16512     \n",
      "                                                                 \n",
      " Final (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17923 (70.01 KB)\n",
      "Trainable params: 17923 (70.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 0.8815 - accuracy: 0.7639 - val_loss: 0.7006 - val_accuracy: 0.7944\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.8181 - val_loss: 0.5610 - val_accuracy: 0.7833\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.8194 - val_loss: 0.5063 - val_accuracy: 0.7944\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.8236 - val_loss: 0.4904 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.8278 - val_loss: 0.4875 - val_accuracy: 0.8000\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8306 - val_loss: 0.4781 - val_accuracy: 0.8167\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8347 - val_loss: 0.4799 - val_accuracy: 0.8167\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8500 - val_loss: 0.4803 - val_accuracy: 0.7944\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8431 - val_loss: 0.4948 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8306 - val_loss: 0.4759 - val_accuracy: 0.8111\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8486 - val_loss: 0.4708 - val_accuracy: 0.8111\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8444 - val_loss: 0.4690 - val_accuracy: 0.8056\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8528 - val_loss: 0.4843 - val_accuracy: 0.8167\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8444 - val_loss: 0.4598 - val_accuracy: 0.8222\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8472 - val_loss: 0.4927 - val_accuracy: 0.8222\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8514 - val_loss: 0.4484 - val_accuracy: 0.8333\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8542 - val_loss: 0.4573 - val_accuracy: 0.8167\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8556 - val_loss: 0.4507 - val_accuracy: 0.8278\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8556 - val_loss: 0.4582 - val_accuracy: 0.8222\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8500 - val_loss: 0.4476 - val_accuracy: 0.8278\n",
      "\n",
      "Evaluation against Test Dataset :\n",
      "------------------------------------\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4129613935947418, 0.8500000238418579]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "symptom_data['ROOT_CAUSE'] = label_encoder.fit_transform(\n",
    "                                symptom_data['ROOT_CAUSE'])\n",
    "\n",
    "#Convert Pandas DataFrame to a numpy vector\n",
    "np_symptom = symptom_data.to_numpy().astype(float)\n",
    "\n",
    "#Extract the feature variables (X)\n",
    "X_data = np_symptom[:,1:8]\n",
    "\n",
    "#Extract the target variable (Y), conver to one-hot-encodign\n",
    "Y_data=np_symptom[:,8]\n",
    "Y_data = tf.keras.utils.to_categorical(Y_data,3)\n",
    "\n",
    "#Split training and test data\n",
    "X_train,X_test,Y_train,Y_test = train_test_split( X_data, Y_data, test_size=0.10)\n",
    "\n",
    "print(\"Shape of feature variables :\", X_train.shape)\n",
    "print(\"Shape of target variable :\",Y_train.shape)\n",
    "\n",
    "#Setup Training Parameters\n",
    "EPOCHS=20\n",
    "BATCH_SIZE=64\n",
    "VERBOSE=1\n",
    "OUTPUT_CLASSES=len(label_encoder.classes_)\n",
    "N_HIDDEN=128\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "#Create a Keras sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "#Add a Dense Layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                             input_shape=(7,),\n",
    "                              name='Dense-Layer-1',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a second dense layer\n",
    "model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                              name='Dense-Layer-2',\n",
    "                              activation='relu'))\n",
    "\n",
    "#Add a softmax layer for categorial prediction\n",
    "model.add(keras.layers.Dense(OUTPUT_CLASSES,\n",
    "                             name='Final',\n",
    "                             activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Build the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "\n",
    "#Evaluate the model against the test dataset and print results\n",
    "\n",
    "\n",
    "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d675f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('root.pkl', 'wb'))\n",
    "model = pickle.load(open('root.pkl', 'rb'))\n",
    "\n",
    "model.save(\"root_cause.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a97286cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "['DATABASE_ISSUE']\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "['DATABASE_ISSUE' 'NETWORK_DELAY' 'MEMORY_LEAK' 'DATABASE_ISSUE'\n",
      " 'DATABASE_ISSUE']\n"
     ]
    }
   ],
   "source": [
    "CPU_LOAD = 1\n",
    "MEMORY_LOAD = 0\n",
    "DELAY = 0\n",
    "ERROR_1000 = 0\n",
    "ERROR_1001 = 1\n",
    "ERROR_1002 = 1\n",
    "ERROR_1003 = 0\n",
    "\n",
    "# Convert the input to a NumPy array\n",
    "input_data = np.array([[CPU_LOAD, MEMORY_LOAD, DELAY, ERROR_1000, ERROR_1001, ERROR_1002, ERROR_1003]])\n",
    "\n",
    "# Make the prediction\n",
    "prediction = np.argmax(model.predict(input_data), axis=1)\n",
    "\n",
    "# Assuming label_encoder is defined elsewhere in your code\n",
    "print(label_encoder.inverse_transform(prediction))\n",
    "# Define the input data as a NumPy array\n",
    "input_data = np.array([\n",
    "    [1, 0, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 1]\n",
    "])\n",
    "\n",
    "# Make predictions as a batch\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "# Convert predictions to labels using argmax and inverse_transform\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "decoded_labels = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "print(decoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee22b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
